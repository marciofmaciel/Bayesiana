import streamlit as st
import numpy as np
from scipy.integrate import trapezoid
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import norm, uniform
from scipy.optimize import minimize

# --- Streamlit Page Configuration ---
st.set_page_config(
    page_title="Infer√™ncia Bayesiana para Comp√≥sitos",
    page_icon="üî¨",
    layout="wide"
)

st.title("üî¨ Infer√™ncia Bayesiana para Caracteriza√ß√£o de Laminados Comp√≥sitos via Ultrassom")
st.markdown("Esta aplica√ß√£o interativa demonstra os conceitos e etapas da infer√™ncia Bayesiana aplicada √† caracteriza√ß√£o de propriedades el√°sticas de comp√≥sitos usando ultrassom.")

# --- Helper Functions (Simulations) ---

# M√≥dulo 1: Simplified Christoffel Solver (Conceptual)
def simulate_christoffel_velocities(C_vals, rho, angle_deg):
    """
    Simula velocidades de onda para um material ortotr√≥pico simplificado.
    N√£o √© um solver Christoffel completo, mas ilustra a depend√™ncia angular.
    Assume propaga√ß√£o no plano 1-2.
    """
    angle_rad = np.deg2rad(angle_deg)
    
    # Simplified C_ij mapping for orthotropic material
    C11, C22, C12, C66 = C_vals
    
    # Simplified velocity calculation (conceptual, not exact Christoffel)
    # Longitudinal-like velocity
    v_longitudinal = np.sqrt((C11 * np.cos(angle_rad)**2 + C22 * np.sin(angle_rad)**2 + 2 * C12 * np.cos(angle_rad) * np.sin(angle_rad) + C66) / rho)
    # Shear-like velocity (simplified)
    v_shear = np.sqrt((C66 * np.cos(angle_rad)**2 + C66 * np.sin(angle_rad)**2) / rho) # Simplified, often C44, C55, C66 are different
    
    return v_longitudinal, v_shear

# M√≥dulo 2: Ultrasonic Signal Simulation
def simulate_ultrasonic_signal(frequency_MHz, duration_us, noise_level, TOF_us):
    """Simula um sinal ultrass√¥nico com ru√≠do e um pulso."""
    sampling_rate_MHz = 100 # 100 MS/s
    time = np.linspace(0, duration_us, int(duration_us * sampling_rate_MHz))
    
    # Simulate a noisy baseline
    signal = np.random.normal(0, noise_level, len(time))
    
    # Simulate a pulse at TOF
    pulse_start_idx = int(TOF_us * sampling_rate_MHz)
    if pulse_start_idx < len(time):
        pulse_duration_samples = int(1.5 * sampling_rate_MHz / frequency_MHz) # ~1.5 cycles
        pulse_amplitude = 1.0
        
        # Ricker wavelet or simple sine burst
        t_pulse = np.linspace(-pulse_duration_samples / sampling_rate_MHz / 2, 
                              pulse_duration_samples / sampling_rate_MHz / 2, 
                              pulse_duration_samples)
        
        # Simple sine burst with Gaussian envelope
        envelope = np.exp(-t_pulse**2 / (2 * (0.2 / frequency_MHz)**2))
        pulse = pulse_amplitude * np.sin(2 * np.pi * frequency_MHz * t_pulse) * envelope
        
        end_idx = pulse_start_idx + len(pulse)
        if end_idx > len(time):
            pulse = pulse[:len(time) - pulse_start_idx]
            end_idx = len(time)
            
        signal[pulse_start_idx:end_idx] += pulse
        
    return time, signal

def calculate_velocity_and_uncertainty(h_mm, delta_h_mm, TOF_us, delta_TOF_us, technique="Transmiss√£o"):
    """Calcula velocidade e propaga incertezas."""
    h_m = h_mm / 1000
    delta_h_m = delta_h_mm / 1000
    TOF_s = TOF_us / 1e6
    delta_TOF_s = delta_TOF_us / 1e6

    if technique == "Transmiss√£o":
        v = h_m / TOF_s
        # Error propagation for v = h/TOF
        delta_v_rel = np.sqrt((delta_h_m / h_m)**2 + (delta_TOF_s / TOF_s)**2)
    else: # Reflex√£o
        v = (2 * h_m) / TOF_s
        # Error propagation for v = 2h/TOF
        delta_v_rel = np.sqrt((delta_h_m / h_m)**2 + (delta_TOF_s / TOF_s)**2)
        
    delta_v = v * delta_v_rel
    return v, delta_v

# M√≥dulo 3: Bayesian Inference Concepts
def simulate_likelihood_prior_posterior(v_exp, sigma_exp, prior_mean, prior_std, param_range=(0, 200)):
    """Simula distribui√ß√µes de prior, likelihood e posterior para um √∫nico par√¢metro."""
    param_values = np.linspace(param_range[0], param_range[1], 500)
    
    # Prior (Gaussian for simplicity)
    prior_dist = norm.pdf(param_values, loc=prior_mean, scale=prior_std)
    
    # Likelihood (assuming v_pred = param_value for simplicity)
    # In a real scenario, v_pred would come from the forward model
    likelihood_dist = norm.pdf(v_exp, loc=param_values, scale=sigma_exp)
    
    # Posterior (unnormalized)
    posterior_unnorm = likelihood_dist * prior_dist
    
    # Normalize posterior for plotting
    posterior_dist = posterior_unnorm / trapezoid(posterior_unnorm, param_values)
    
    return param_values, prior_dist, likelihood_dist, posterior_dist

# M√≥dulo 4: MCMC Simulation
def simulate_mcmc_chain(num_iterations, step_size, true_value, initial_value, likelihood_std, prior_mean, prior_std):
    """Simula uma cadeia MCMC Metropolis-Hastings para um √∫nico par√¢metro."""
    samples = np.zeros(num_iterations)
    current_param = initial_value
    accepted_count = 0

    # Simplified log-posterior function for a single parameter
    def log_posterior_func(param):
        if not (0 < param < 200): # Simple bounds
            return -np.inf
        log_prior = norm.logpdf(param, loc=prior_mean, scale=prior_std)
        # Simulate likelihood: assume true_value is the "measured" value
        log_likelihood = norm.logpdf(true_value, loc=param, scale=likelihood_std)
        return log_prior + log_likelihood

    current_log_post = log_posterior_func(current_param)

    for i in range(num_iterations):
        # Propose a new parameter value
        proposed_param = current_param + np.random.normal(0, step_size)
        
        # Calculate log-posterior for proposed value
        proposed_log_post = log_posterior_func(proposed_param)
        
        # Calculate acceptance ratio
        alpha = np.exp(proposed_log_post - current_log_post)
        
        # Accept or reject
        if np.random.rand() < alpha:
            current_param = proposed_param
            current_log_post = proposed_log_post
            accepted_count += 1
        
        samples[i] = current_param
        
    acceptance_rate = accepted_count / num_iterations
    
    # Simulate R_hat and ESS (conceptual values for demonstration)
    r_hat = 1.0 + (np.random.rand() * 0.2 if acceptance_rate < 0.2 or acceptance_rate > 0.5 else np.random.rand() * 0.05)
    ess = num_iterations * (acceptance_rate * 0.5) # Simplified relation
    
    return samples, acceptance_rate, r_hat, ess

# M√≥dulo 5: Sensitivity and Validation
def simulate_posterior_samples(num_samples, prior_mean, prior_std, true_value, likelihood_std, correlation_strength=0.0):
    """Simula amostras posteriores para 2 par√¢metros com correla√ß√£o."""
    # Simulate a more informative posterior than prior
    posterior_std = prior_std / (1 + np.random.rand() * 2) # Posterior is narrower
    
    # Simulate samples for C11
    C11_samples = np.random.normal(true_value, posterior_std, num_samples)
    
    # Simulate samples for C12, potentially correlated with C11
    if correlation_strength != 0:
        # Create correlated samples
        mean = [true_value, true_value * 0.05] # C12 is typically much smaller than C11
        cov = [[posterior_std**2, correlation_strength * posterior_std * (posterior_std/5)], 
               [correlation_strength * posterior_std * (posterior_std/5), (posterior_std/5)**2]]
        
        samples_2d = np.random.multivariate_normal(mean, cov, num_samples)
        C11_samples = samples_2d[:, 0]
        C12_samples = samples_2d[:, 1]
    else:
        C12_samples = np.random.normal(true_value * 0.05, posterior_std / 5, num_samples)

    # Simulate prior samples for comparison
    C11_prior_samples = np.random.normal(prior_mean, prior_std, num_samples)
    C12_prior_samples = np.random.normal(prior_mean * 0.05, prior_std / 5, num_samples)
    
    return C11_samples, C12_samples, C11_prior_samples, C12_prior_samples

# --- Module Functions ---

def module1_fundamentals():
    st.header("M√≥dulo 1: Fundamentos de Propaga√ß√£o de Ondas")
    st.markdown("""
    Este m√≥dulo explora como as propriedades el√°sticas de um comp√≥sito anisotr√≥pico afetam a velocidade de propaga√ß√£o das ondas ultrass√¥nicas.
    A Equa√ß√£o de Christoffel √© a base para relacionar as constantes el√°sticas (C_ij) com as velocidades de onda em diferentes dire√ß√µes.
    """)

    st.subheader("Par√¢metros do Material (Simplificado)")
    col1, col2 = st.columns(2)
    with col1:
        C11 = st.slider("C‚ÇÅ‚ÇÅ (GPa)", 50, 200, 140, 5) * 1e9
        C22 = st.slider("C‚ÇÇ‚ÇÇ (GPa)", 5, 20, 10, 1) * 1e9
        C12 = st.slider("C‚ÇÅ‚ÇÇ (GPa)", 2, 10, 5, 1) * 1e9
    with col2:
        C66 = st.slider("C‚ÇÜ‚ÇÜ (GPa)", 3, 15, 7, 1) * 1e9
        rho = st.slider("Densidade (kg/m¬≥)", 1000, 2000, 1550, 50)
        
    st.subheader("Dire√ß√£o de Propaga√ß√£o")
    angle_deg = st.slider("√Çngulo de Propaga√ß√£o (graus no plano 1-2)", 0, 90, 0, 5)

    if st.button("Calcular Velocidades"):
        C_vals = (C11, C22, C12, C66)
        v_long, v_shear = simulate_christoffel_velocities(C_vals, rho, angle_deg)
        
        st.write(f"**Velocidade Longitudinal (simulada):** {v_long/1000:.2f} km/s")
        st.write(f"**Velocidade Cisalhante (simulada):** {v_shear/1000:.2f} km/s")
        
        st.markdown("---")
        st.subheader("Depend√™ncia Angular da Velocidade (Exemplo Conceitual)")
        angles = np.linspace(0, 90, 19)
        v_long_plot = []
        v_shear_plot = []
        for a in angles:
            vl, vs = simulate_christoffel_velocities(C_vals, rho, a)
            v_long_plot.append(vl / 1000)
            v_shear_plot.append(vs / 1000)
            
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(angles, v_long_plot, label="Velocidade Longitudinal", marker='o')
        ax.plot(angles, v_shear_plot, label="Velocidade Cisalhante", marker='x')
        ax.set_xlabel("√Çngulo de Propaga√ß√£o (graus)")
        ax.set_ylabel("Velocidade (km/s)")
        ax.set_title("Velocidade de Onda vs. √Çngulo de Propaga√ß√£o (Simulado)")
        ax.legend()
        ax.grid(True)
        st.pyplot(fig)
        plt.close(fig)

def module2_ultrasound_measurement():
    st.header("M√≥dulo 2: Medi√ß√£o por Ultrassom e Incertezas")
    st.markdown("""
    Este m√≥dulo demonstra como as velocidades de onda s√£o extra√≠das de sinais ultrass√¥nicos e como as incertezas experimentais s√£o propagadas.
    """)

    st.subheader("Par√¢metros da Medi√ß√£o")
    col1, col2 = st.columns(2)
    with col1:
        h_mm = st.slider("Espessura da Amostra (mm)", 1.0, 10.0, 5.0, 0.1)
        delta_h_mm = st.slider("Incerteza na Espessura (mm)", 0.01, 0.1, 0.05, 0.01)
    with col2:
        TOF_us = st.slider("Tempo de Voo (TOF) (¬µs)", 1.0, 5.0, 2.5, 0.1)
        delta_TOF_us = st.slider("Incerteza no TOF (¬µs)", 0.001, 0.1, 0.02, 0.001)
    
    technique = st.radio("T√©cnica de Medi√ß√£o", ["Transmiss√£o", "Reflex√£o"])

    if st.button("Calcular Velocidade e Incerteza"):
        v, delta_v = calculate_velocity_and_uncertainty(h_mm, delta_h_mm, TOF_us, delta_TOF_us, technique)
        
        st.write(f"**Velocidade Calculada:** {v:.2f} m/s")
        st.write(f"**Incerteza na Velocidade:** ¬± {delta_v:.2f} m/s ({delta_v/v*100:.2f}%)")
        
        st.markdown("---")
        st.subheader("Sinal Ultrass√¥nico Simulado")
        
        freq_MHz = st.slider("Frequ√™ncia do Transdutor (MHz)", 1.0, 10.0, 5.0, 0.5)
        noise_lvl = st.slider("N√≠vel de Ru√≠do", 0.01, 0.5, 0.1, 0.01)
        
        time_signal, signal_data = simulate_ultrasonic_signal(freq_MHz, TOF_us * 2, noise_lvl, TOF_us)
        
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.plot(time_signal, signal_data)
        ax.axvline(x=TOF_us, color='r', linestyle='--', label=f'TOF = {TOF_us} ¬µs')
        ax.set_xlabel("Tempo (¬µs)")
        ax.set_ylabel("Amplitude")
        ax.set_title("Sinal Ultrass√¥nico Simulado")
        ax.legend()
        ax.grid(True)
        st.pyplot(fig)
        plt.close(fig)

def module3_bayesian_inference():
    st.header("M√≥dulo 3: Infer√™ncia Bayesiana: Conceitos")
    st.markdown("""
    Este m√≥dulo ilustra os componentes fundamentais da infer√™ncia Bayesiana: o Prior, a Likelihood e a Posterior.
    Vamos simular a estimativa de um √∫nico par√¢metro (e.g., C‚ÇÅ‚ÇÅ) a partir de uma medi√ß√£o.
    """)

    st.subheader("Dados Observados (Simulados)")
    v_exp = st.slider("Velocidade Medida (v_exp, m/s)", 1000, 10000, 7400, 100)
    sigma_exp = st.slider("Incerteza da Medi√ß√£o (œÉ_exp, m/s)", 10, 200, 50, 10)

    st.subheader("Conhecimento Pr√©-existente (Prior)")
    prior_mean = st.slider("M√©dia do Prior (m/s)", 1000, 10000, 7000, 100)
    prior_std = st.slider("Desvio Padr√£o do Prior (m/s)", 100, 2000, 1000, 100)
    
    param_range_min = min(v_exp - 3*sigma_exp, prior_mean - 3*prior_std) - 500
    param_range_max = max(v_exp + 3*sigma_exp, prior_mean + 3*prior_std) + 500
    
    if st.button("Visualizar Distribui√ß√µes"):
        param_values, prior_dist, likelihood_dist, posterior_dist = \
            simulate_likelihood_prior_posterior(v_exp, sigma_exp, prior_mean, prior_std, 
                                                param_range=(param_range_min, param_range_max))
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(param_values, prior_dist, label="Prior", linestyle='--')
        ax.plot(param_values, likelihood_dist, label="Likelihood")
        ax.plot(param_values, posterior_dist, label="Posterior", linewidth=2, color='red')
        
        ax.axvline(x=v_exp, color='gray', linestyle=':', label=f'v_exp = {v_exp} m/s')
        
        ax.set_xlabel("Valor do Par√¢metro (e.g., C‚ÇÅ‚ÇÅ equivalente em m/s)")
        ax.set_ylabel("Densidade de Probabilidade")
        ax.set_title("Prior, Likelihood e Posterior (Conceitual)")
        ax.legend()
        ax.grid(True)
        st.pyplot(fig)
        plt.close(fig)
        
        st.markdown("---")
        st.subheader("Interpreta√ß√£o")
        st.write(f"**M√©dia do Prior:** {prior_mean:.0f} m/s, **SD do Prior:** {prior_std:.0f} m/s")
        st.write(f"**M√©dia da Likelihood (dada v_exp):** {v_exp:.0f} m/s, **SD da Likelihood:** {sigma_exp:.0f} m/s")
        
        posterior_mean = trapezoid(param_values * posterior_dist, param_values)
        posterior_std = np.sqrt(trapezoid((param_values - posterior_mean)**2 * posterior_dist, param_values))
        
        st.write(f"**M√©dia da Posterior:** {posterior_mean:.0f} m/s, **SD da Posterior:** {posterior_std:.0f} m/s")
        st.markdown(f"""
        - O **Prior** representa nosso conhecimento inicial sobre o par√¢metro.
        - A **Likelihood** mostra qu√£o prov√°veis s√£o os dados observados para cada valor poss√≠vel do par√¢metro.
        - A **Posterior** √© a combina√ß√£o do Prior e da Likelihood, representando nosso conhecimento atualizado sobre o par√¢metro ap√≥s observar os dados.
        - Observe como a posterior √© mais estreita que o prior, indicando uma **redu√ß√£o da incerteza** devido aos dados.
        """)

def module4_mcmc_algorithms():
    st.header("M√≥dulo 4: Algoritmos MCMC em A√ß√£o")
    st.markdown("""
    Este m√≥dulo demonstra o funcionamento do algoritmo Metropolis-Hastings para amostrar a distribui√ß√£o posterior.
    """)

    st.subheader("Configura√ß√£o MCMC (para um √∫nico par√¢metro)")
    col1, col2 = st.columns(2)
    with col1:
        num_iterations = st.slider("N√∫mero de Itera√ß√µes", 1000, 50000, 10000, 1000)
        step_size = st.slider("Tamanho do Passo (Step Size)", 0.1, 100.0, 10.0, 0.1)
        initial_value = st.slider("Valor Inicial da Cadeia", 1000, 10000, 6000, 100)
    with col2:
        true_value = st.slider("Valor 'Verdadeiro' Simulado (para Likelihood)", 1000, 10000, 7400, 100)
        likelihood_std = st.slider("Desvio Padr√£o da Likelihood", 10, 200, 50, 10)
        prior_mean = st.slider("M√©dia do Prior (para MCMC)", 1000, 10000, 7000, 100)
        prior_std = st.slider("Desvio Padr√£o do Prior (para MCMC)", 100, 2000, 1000, 100)

    if st.button("Rodar MCMC"):
        samples, acceptance_rate, r_hat, ess = simulate_mcmc_chain(
            num_iterations, step_size, true_value, initial_value, likelihood_std, prior_mean, prior_std
        )
        
        st.markdown("---")
        st.subheader("Resultados da Cadeia MCMC")
        
        col_metrics1, col_metrics2 = st.columns(2)
        with col_metrics1:
            st.metric("Taxa de Aceita√ß√£o", f"{acceptance_rate*100:.2f}%")
            st.metric("RÃÇ (Gelman-Rubin)", f"{r_hat:.2f}")
        with col_metrics2:
            st.metric("ESS (Effective Sample Size)", f"{int(ess)}")
            
        st.markdown("""
        **Interpreta√ß√£o das M√©tricas:**
        - **Taxa de Aceita√ß√£o:** Idealmente entre 20-40%. Baixa demais indica passos muito grandes; alta demais indica passos muito pequenos.
        - **RÃÇ (Gelman-Rubin):** Deve ser pr√≥ximo de 1.00 (tipicamente < 1.05) para indicar converg√™ncia.
        - **ESS:** N√∫mero de amostras independentes efetivas. Deve ser alto o suficiente (ex: > 400) para infer√™ncias confi√°veis.
        """)

        # Trace Plot
        fig1, ax1 = plt.subplots(figsize=(10, 4))
        ax1.plot(samples)
        ax1.set_xlabel("Itera√ß√£o")
        ax1.set_ylabel("Valor do Par√¢metro")
        ax1.set_title("Trace Plot da Cadeia MCMC")
        ax1.grid(True)
        st.pyplot(fig1)
        plt.close(fig1)

        # Histograma da Posterior
        fig2, ax2 = plt.subplots(figsize=(10, 4))
        sns.histplot(samples[int(num_iterations*0.2):], kde=True, ax=ax2, color='skyblue') # Discard burn-in
        ax2.axvline(x=true_value, color='red', linestyle='--', label="Valor 'Verdadeiro' Simulado")
        ax2.set_xlabel("Valor do Par√¢metro")
        ax2.set_ylabel("Frequ√™ncia")
        ax2.set_title("Distribui√ß√£o Posterior Amostrada (ap√≥s Burn-in)")
        ax2.legend()
        st.pyplot(fig2)
        plt.close(fig2)

def module5_sensitivity_validation():
    st.header("M√≥dulo 5: An√°lise de Sensibilidade e Valida√ß√£o")
    st.markdown("""
    Este m√≥dulo explora como avaliar a identificabilidade dos par√¢metros, o impacto das correla√ß√µes e a valida√ß√£o do modelo.
    """)

    st.subheader("Simula√ß√£o de Amostras Posteriores")
    num_samples = st.slider("N√∫mero de Amostras Posteriores", 1000, 10000, 5000, 1000)
    prior_mean_C11 = st.slider("M√©dia do Prior C‚ÇÅ‚ÇÅ", 100, 200, 140, 5)
    prior_std_C11 = st.slider("Desvio Padr√£o do Prior C‚ÇÅ‚ÇÅ", 10, 50, 30, 5)
    true_value_C11 = st.slider("Valor 'Verdadeiro' Simulado C‚ÇÅ‚ÇÅ", 100, 200, 138, 5)
    likelihood_std_C11 = st.slider("Desvio Padr√£o da Likelihood C‚ÇÅ‚ÇÅ", 1, 10, 3, 1)
    
    correlation_strength = st.slider("For√ßa da Correla√ß√£o C‚ÇÅ‚ÇÅ-C‚ÇÅ‚ÇÇ", -0.99, 0.99, -0.7, 0.05)

    if st.button("Analisar Sensibilidade e Correla√ß√£o"):
        C11_post_samples, C12_post_samples, C11_prior_samples, C12_prior_samples = \
            simulate_posterior_samples(num_samples, prior_mean_C11, prior_std_C11, 
                                       true_value_C11, likelihood_std_C11, correlation_strength)
        
        st.markdown("---")
        st.subheader("1. Identificabilidade (Compara√ß√£o Prior vs. Posterior)")
        
        col_id1, col_id2 = st.columns(2)
        with col_id1:
            st.write(f"**C‚ÇÅ‚ÇÅ:**")
            st.write(f"SD Prior: {np.std(C11_prior_samples):.2f}")
            st.write(f"SD Posterior: {np.std(C11_post_samples):.2f}")
            sd_ratio_C11 = np.std(C11_prior_samples) / np.std(C11_post_samples)
            st.write(f"Raz√£o SD (Prior/Posterior): {sd_ratio_C11:.2f}")
            st.markdown(f"**Interpreta√ß√£o C‚ÇÅ‚ÇÅ:** {'Bem identific√°vel' if sd_ratio_C11 > 5 else ('Moderadamente identific√°vel' if sd_ratio_C11 > 2 else 'Mal identific√°vel')}")
        
        with col_id2:
            st.write(f"**C‚ÇÅ‚ÇÇ:**")
            st.write(f"SD Prior: {np.std(C12_prior_samples):.2f}")
            st.write(f"SD Posterior: {np.std(C12_post_samples):.2f}")
            sd_ratio_C12 = np.std(C12_prior_samples) / np.std(C12_post_samples)
            st.write(f"Raz√£o SD (Prior/Posterior): {sd_ratio_C12:.2f}")
            st.markdown(f"**Interpreta√ß√£o C‚ÇÅ‚ÇÇ:** {'Bem identific√°vel' if sd_ratio_C12 > 5 else ('Moderadamente identific√°vel' if sd_ratio_C12 > 2 else 'Mal identific√°vel')}")

        fig_id, ax_id = plt.subplots(1, 2, figsize=(12, 4))
        sns.histplot(C11_prior_samples, kde=True, color='blue', label='Prior C‚ÇÅ‚ÇÅ', ax=ax_id[0], stat='density', alpha=0.5)
        sns.histplot(C11_post_samples, kde=True, color='red', label='Posterior C‚ÇÅ‚ÇÅ', ax=ax_id[0], stat='density', alpha=0.7)
        ax_id[0].set_title("Prior vs. Posterior para C‚ÇÅ‚ÇÅ")
        ax_id[0].legend()

        sns.histplot(C12_prior_samples, kde=True, color='blue', label='Prior C‚ÇÅ‚ÇÇ', ax=ax_id[1], stat='density', alpha=0.5)
        sns.histplot(C12_post_samples, kde=True, color='red', label='Posterior C‚ÇÅ‚ÇÇ', ax=ax_id[1], stat='density', alpha=0.7)
        ax_id[1].set_title("Prior vs. Posterior para C‚ÇÅ‚ÇÇ")
        ax_id[1].legend()
        st.pyplot(fig_id)
        plt.close(fig_id)

        st.markdown("---")
        st.subheader("2. Impacto da Correla√ß√£o Extrema")
        
        # Calculate correlation
        correlation_matrix = np.corrcoef(C11_post_samples, C12_post_samples)
        st.write(f"**Correla√ß√£o Posterior (C‚ÇÅ‚ÇÅ, C‚ÇÅ‚ÇÇ):** {correlation_matrix[0, 1]:.2f}")
        
        fig_corr, ax_corr = plt.subplots(figsize=(8, 6))
        sns.scatterplot(x=C11_post_samples, y=C12_post_samples, ax=ax_corr, alpha=0.3)
        ax_corr.set_xlabel("C‚ÇÅ‚ÇÅ")
        ax_corr.set_ylabel("C‚ÇÅ‚ÇÇ")
        ax_corr.set_title("Scatter Plot das Amostras Posteriores (C‚ÇÅ‚ÇÅ vs C‚ÇÅ‚ÇÇ)")
        st.pyplot(fig_corr)
        plt.close(fig_corr)
        
        st.markdown(f"""
        Uma correla√ß√£o de **{correlation_matrix[0, 1]:.2f}** entre C‚ÇÅ‚ÇÅ e C‚ÇÅ‚ÇÇ indica uma forte depend√™ncia.
        - **Impacto nas Marginais:** As distribui√ß√µes marginais (histogramas individuais) podem parecer razo√°veis, mas n√£o capturam o "trade-off" entre os par√¢metros.
        - **Impacto nos Intervalos Conjuntos:** A regi√£o de credibilidade conjunta (vis√≠vel no scatter plot) √© alongada e estreita. Isso significa que, embora individualmente C‚ÇÅ‚ÇÅ e C‚ÇÅ‚ÇÇ possam ter uma certa faixa de valores, apenas combina√ß√µes espec√≠ficas ao longo da linha de correla√ß√£o s√£o plaus√≠veis. Ignorar essa correla√ß√£o pode levar a conclus√µes enganosas sobre a variabilidade real dos par√¢metros.
        """)

        st.markdown("---")
        st.subheader("3. Posterior Predictive Check (PPC)")
        st.markdown("""
        O PPC verifica se o modelo √© capaz de gerar dados semelhantes aos observados.
        Aqui, simulamos dados preditivos e os comparamos com um valor "observado" simulado.
        """)
        
        # Simulate observed data for PPC
        sim_observed_v = np.random.normal(true_value_C11, likelihood_std_C11)
        
        # Simulate predictive data from posterior samples
        sim_predictive_v = np.random.normal(C11_post_samples, likelihood_std_C11)
        
        fig_ppc, ax_ppc = plt.subplots(figsize=(10, 6))
        sns.histplot(sim_predictive_v, kde=True, color='green', label='Dados Preditivos', ax=ax_ppc, stat='density', alpha=0.7)
        ax_ppc.axvline(x=sim_observed_v, color='red', linestyle='--', label='Dado Observado Simulado')
        ax_ppc.set_xlabel("Velocidade (m/s)")
        ax_ppc.set_ylabel("Densidade")
        ax_ppc.set_title("Posterior Predictive Check (PPC) para C‚ÇÅ‚ÇÅ")
        ax_ppc.legend()
        st.pyplot(fig_ppc)
        plt.close(fig_ppc)
        
        # Calculate p-value for PPC (conceptual)
        p_value_ppc = np.mean(sim_predictive_v > sim_observed_v)
        st.markdown(f"""
        - O **Dado Observado Simulado** √© o valor que o modelo tenta explicar.
        - Os **Dados Preditivos** s√£o gerados usando os par√¢metros amostrados da posterior.
        - Se o dado observado cair dentro da distribui√ß√£o dos dados preditivos (especialmente perto do centro), o modelo √© considerado **adequado**.
        - Um p-valor preditivo de **{p_value_ppc:.2f}** (propor√ß√£o de dados preditivos maiores que o observado) indica que o modelo √© {'adequado' if 0.05 < p_value_ppc < 0.95 else 'potencialmente inadequado'}.
        """)


# --- Main App Navigation ---
st.sidebar.title("Navega√ß√£o")
selected_module = st.sidebar.radio(
    "Escolha um M√≥dulo",
    [
        "M√≥dulo 1: Fundamentos",
        "M√≥dulo 2: Medi√ß√£o Ultrass√¥nica",
        "M√≥dulo 3: Infer√™ncia Bayesiana",
        "M√≥dulo 4: Algoritmos MCMC",
        "M√≥dulo 5: Sensibilidade e Valida√ß√£o"
    ]
)

if selected_module == "M√≥dulo 1: Fundamentos":
    module1_fundamentals()
elif selected_module == "M√≥dulo 2: Medi√ß√£o Ultrass√¥nica":
    module2_ultrasound_measurement()
elif selected_module == "M√≥dulo 3: Infer√™ncia Bayesiana":
    module3_bayesian_inference()
elif selected_module == "M√≥dulo 4: Algoritmos MCMC":
    module4_mcmc_algorithms()
elif selected_module == "M√≥dulo 5: Sensibilidade e Valida√ß√£o":
    module5_sensitivity_validation()